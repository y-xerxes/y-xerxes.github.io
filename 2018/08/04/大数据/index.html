<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="[TOC]
zookeeper配置文件1.把zookeeper文件夹复制三份，我们仅修改\conf\zoo.cfg
    tickTime=2000
    initLimit=5
    syncLimit=2
    dataDir=/usr/local/zk0/data
    dataLogDir=/usr/local/zk0/logs
    clientPort=2184
    s">
<meta property="og:type" content="article">
<meta property="og:title" content="大数据">
<meta property="og:url" content="http://yoursite.com/child/2018/08/04/大数据/index.html">
<meta property="og:site_name" content="y-xerxes's Blog">
<meta property="og:description" content="[TOC]
zookeeper配置文件1.把zookeeper文件夹复制三份，我们仅修改\conf\zoo.cfg
    tickTime=2000
    initLimit=5
    syncLimit=2
    dataDir=/usr/local/zk0/data
    dataLogDir=/usr/local/zk0/logs
    clientPort=2184
    s">
<meta property="og:updated_time" content="2018-10-11T14:10:43.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="大数据">
<meta name="twitter:description" content="[TOC]
zookeeper配置文件1.把zookeeper文件夹复制三份，我们仅修改\conf\zoo.cfg
    tickTime=2000
    initLimit=5
    syncLimit=2
    dataDir=/usr/local/zk0/data
    dataLogDir=/usr/local/zk0/logs
    clientPort=2184
    s">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/child/2018/08/04/大数据/"/>





  <title> 大数据 | y-xerxes's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">y-xerxes's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2018/08/04/大数据/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xerxes">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="file:///Users/zhangyaxing/Desktop/hexo/猫头.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="y-xerxes's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                大数据
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-04T19:46:26+08:00">
                2018-08-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>[TOC]</p>
<h1 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h1><h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><pre><code>1.把zookeeper文件夹复制三份，我们仅修改\conf\zoo.cfg
    tickTime=2000
    initLimit=5
    syncLimit=2
    dataDir=/usr/local/zk0/data
    dataLogDir=/usr/local/zk0/logs
    clientPort=2184
    server.0=127.0.0.1:8880:7770
    server.1=127.0.0.1:8881:7771
    server.2=127.0.0.1:8882:7772
2.分别在文件夹/tmp/zookeeper/data00,data01和data02下面新建myid文件，文件内容只有一个数字，代表zookeeper节点的唯一id，即要确保此id在集群内唯一，且要跟配置文件中的server.0、server.1、server.2 对应上。
</code></pre><h3 id="命令行操作"><a href="#命令行操作" class="headerlink" title="命令行操作"></a>命令行操作</h3><pre><code>./zkServer.sh start &amp; #启动zookeeper服务器
./zkServer.sh status#查看状态
./zkCli.sh -server 127.0.0.1:2182 #启动客户端
</code></pre><h1 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h1><h3 id="配置文件-1"><a href="#配置文件-1" class="headerlink" title="配置文件"></a>配置文件</h3><pre><code>仅仅修改server.properties文件，把\config\server.properties文件复制2份，分别是server.properties，server_1.properties，server_2.properties，

0.文件server.properties
    broker.id=0
    listeners=PLAINTEXT://localhost:9092
    log.dirs=/tmp/kafka-logs-0
    num.partitions=3
    zookeeper.connect=localhost:2184,localhost:2182,localhost:2183

1.文件server_1.properties
    broker.id=1
    listeners=PLAINTEXT://localhost:9093
    log.dirs=/tmp/kafka-logs-1
    num.partitions=3
    zookeeper.connect=localhost:2184,localhost:2182,localhost:2183

2.文件server_2.properties
    broker.id=2
    listeners=PLAINTEXT://localhost:9094
    log.dirs=/tmp/kafka-logs-2
    num.partitions=3
    zookeeper.connect=localhost:2184,localhost:2182,localhost:2183
</code></pre><h3 id="启动kafka-broker"><a href="#启动kafka-broker" class="headerlink" title="启动kafka broker"></a>启动kafka broker</h3><pre><code>bin/kafka-server-start.sh -daemon config/server.properties
bin/kafka-server-start.sh -daemon config/server_1.properties
bin/kafka-server-start.sh -daemon config/server_2.properties
</code></pre><h3 id="创建topic"><a href="#创建topic" class="headerlink" title="创建topic"></a>创建topic</h3><pre><code>bin/kafka-topics.sh --create --zookeeper localhost:2182 --replication-factor 3 --partitions 1 --topic mytopic
</code></pre><h3 id="创建后，使用-–describe-来查看一下"><a href="#创建后，使用-–describe-来查看一下" class="headerlink" title="创建后，使用 –describe 来查看一下"></a>创建后，使用 –describe 来查看一下</h3><pre><code>bin/kafka-topics.sh --describe --zookeeper localhost:2182 --topic mytopic
</code></pre><h3 id="现在我们分别在两个终端上运行下面的命令来测试生产消息和消费消息。"><a href="#现在我们分别在两个终端上运行下面的命令来测试生产消息和消费消息。" class="headerlink" title="现在我们分别在两个终端上运行下面的命令来测试生产消息和消费消息。"></a>现在我们分别在两个终端上运行下面的命令来测试生产消息和消费消息。</h3><pre><code># 终端 A 生产消息
$ bin/kafka-console-producer.sh --broker-list localhost:9092 --topic mytopic
# 终端 B 消费消息
$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic mytopic
</code></pre><h1 id="flume"><a href="#flume" class="headerlink" title="flume"></a>flume</h1><h3 id="配置文件-2"><a href="#配置文件-2" class="headerlink" title="配置文件"></a>配置文件</h3><pre><code>1.修改 flume-env.sh 配置文件,主要是JAVA_HOME变量设置
2.cp conf/flume-conf.properties.template conf/exec.conf
    示例：
        # Name the components(成分) on this agent
        a2.sources = r2
        a2.sinks = k2
        a2.channels = c2
        # Describe/configure the source
        a2.sources.r2.type = exec
        a2.sources.r2.channels = c2
        a2.sources.r2.command=tail -n +0 -F /Users/zhangyaxing/Desktop/flume-1.6.0/test.log
        # Describe the sink
        a2.sinks.k2.type = logger
        # Use a channel which buffers events in memory
        a2.channels.c2.type = memory
        a2.channels.c2.capacity = 1000
        a2.channels.c2.transactionCapacity = 100
        # Bind the source and sink to the channel
        a2.sources.r2.channels = c2
        a2.sinks.k2.channel = c2
</code></pre><h3 id="命令行操作-1"><a href="#命令行操作-1" class="headerlink" title="命令行操作"></a>命令行操作</h3><pre><code>验证安装：
    flume-ng version
启动flume：
    flume-ng agent --conf conf/ -f conf/exec.conf -Dflume.root.logger=DEBUG,console -n a2
</code></pre><h1 id="flume-—–-gt-kafka"><a href="#flume-—–-gt-kafka" class="headerlink" title="flume —–&gt; kafka"></a>flume —–&gt; kafka</h1><blockquote>
<p>Flume与Kafka整合就是接口的实现，将Kafka的producer API实现为Flume的sink。简单理解就是将Flume的输出（sinks）作为Kafka的输入（producer）。</p>
<h3 id="配置文件-3"><a href="#配置文件-3" class="headerlink" title="配置文件"></a>配置文件</h3><pre><code>a1.sources = s1
a1.sinks = k1
a1.channels = c1
# a1 : name of agent
# Describe/configure the source
a1.sources.s1.type=exec
a1.sources.s1.command=tail -F /Users/zhangyaxing/Desktop/flume-1.6.0/test.log
a1.sources.s1.channels=c1
# Describe the sink
a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k1.topic = flumeTest  
a1.sinks.k1.brokerList = localhost:9092,localhost:9093,localhost:9094
agent.sinks.k1.serializer.class=kafka.serializer.StringEncoder  
a1.sinks.k1.channel = c1 
# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 10000
a1.channels.c1.transactionCapacity = 100
# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
</code></pre><h3 id="启动flume连接到kafka"><a href="#启动flume连接到kafka" class="headerlink" title="启动flume连接到kafka"></a>启动flume连接到kafka</h3><pre><code>flume-ng agent -n a1 -c conf/ -f conf/flume-conf.properties -Dflume.root.logger=INFO,console  
</code></pre><h3 id="启动kafka消费者接受数据"><a href="#启动kafka消费者接受数据" class="headerlink" title="启动kafka消费者接受数据"></a>启动kafka消费者接受数据</h3><pre><code>kafka-console-consumer.sh --zookeeper localhost:2182,localhost:2183,localhost:2184 --topic flumeTest --from-beginning
</code></pre></blockquote>
<h1 id="kafka-—–-gt-spark-streaming"><a href="#kafka-—–-gt-spark-streaming" class="headerlink" title="kafka —–&gt; spark streaming"></a>kafka —–&gt; spark streaming</h1><h3 id="什么是Spark-Streaming"><a href="#什么是Spark-Streaming" class="headerlink" title="什么是Spark Streaming"></a>什么是Spark Streaming</h3><blockquote>
<p>流式处理是把连续不断的数据输入分割成单元数据块来处理。<br>Spark Streaming对Spark核心API进行了相应的扩展，支持高吞吐、低延迟、可扩展的流式数据处理。</p>
</blockquote>
<h3 id="自己管理offset"><a href="#自己管理offset" class="headerlink" title="自己管理offset"></a>自己管理offset</h3><blockquote>
<p>为了让Spark Streaming消费kafka的数据不丢数据，可以创建Kafka Direct DStream，由Spark Streaming自己管理offset，并不是存到zookeeper。启用S​​park Streaming的 checkpoints是存储偏移量的最简单方法，因为它可以在Spark的框架内轻松获得。 checkpoints将应用程序的状态保存到HDFS，以便在故障时可以恢复。如果发生故障，Spark Streaming应用程序可以从checkpoints偏移范围读取消息。但是，Spark Streaming checkpoints在应用程序修改后由于从checkpoint反序列化失败而无法恢复，因此不是非常可靠，特别是如果您将此机制用于关键生产应用程序，另外，基于zookeeper的offset可视化工具将无法使用。我们不建议通过Spark checkpoints来管理偏移量。因此本文将手动存储offset到zookeeper，完全自我掌控offset。</p>
</blockquote>
<h3 id="编写代码"><a href="#编写代码" class="headerlink" title="编写代码"></a>编写代码</h3><pre><code>KafkaManager.scala
</code></pre><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> org.apache.spark.streaming.kafka</div><div class="line"><span class="keyword">import</span> kafka.common.<span class="type">TopicAndPartition</span></div><div class="line"><span class="keyword">import</span> kafka.message.<span class="type">MessageAndMetadata</span></div><div class="line"><span class="keyword">import</span> kafka.serializer.<span class="type">Decoder</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkException</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming.<span class="type">StreamingContext</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.<span class="type">InputDStream</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka.<span class="type">KafkaCluster</span>.<span class="type">LeaderOffset</span></div><div class="line"><span class="keyword">import</span> scala.reflect.<span class="type">ClassTag</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">KafkaManager</span>(<span class="params">val kafkaParams: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]</span>) <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</div><div class="line">  <span class="comment">// KafkaCluster in Spark is overwrited by myself</span></div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> kc = <span class="keyword">new</span> <span class="type">KafkaCluster</span>(kafkaParams)</div><div class="line">  <span class="comment">//根据offset创建DStream</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">createDirectStream</span></span>[<span class="type">K</span>: <span class="type">ClassTag</span>,</div><div class="line">                        <span class="type">V</span>: <span class="type">ClassTag</span>,</div><div class="line">                        <span class="type">KD</span> &lt;: <span class="type">Decoder</span>[<span class="type">K</span>]: <span class="type">ClassTag</span>,</div><div class="line">                        <span class="type">VD</span> &lt;: <span class="type">Decoder</span>[<span class="type">V</span>]: <span class="type">ClassTag</span></div><div class="line">                        ](ssc: <span class="type">StreamingContext</span>,</div><div class="line">                          kafkaParams: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>],</div><div class="line">                          topics: <span class="type">Set</span>[<span class="type">String</span>]): <span class="type">InputDStream</span>[(<span class="type">K</span>, <span class="type">V</span>, <span class="type">String</span>)] = &#123;</div><div class="line">    <span class="keyword">val</span> groupId = kafkaParams.get(<span class="string">"group.id"</span>).get</div><div class="line">    <span class="comment">//在zookeeper上读取offsets前先根据实际情况更新offsets</span></div><div class="line">    setOrUpdateOffsets(topics, groupId)</div><div class="line">    <span class="comment">//从zookeeper上读取offset开始消费message</span></div><div class="line">    <span class="keyword">val</span> messages = &#123;</div><div class="line">      <span class="keyword">val</span> partitionsE = kc.getPartitions(topics)</div><div class="line">      <span class="keyword">if</span>(partitionsE.isLeft)</div><div class="line">        <span class="comment">// s"xx $&#123;&#125;" 字符串插值</span></div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"get kafka partition failed: <span class="subst">$&#123;partitionsE.left.get&#125;</span>"</span>)</div><div class="line">      <span class="keyword">val</span> partitions = partitionsE.right.get</div><div class="line">      <span class="keyword">val</span> consumerOffsetsE = kc.getConsumerOffsets(groupId, partitions)</div><div class="line">      <span class="keyword">if</span>(consumerOffsetsE.isLeft)</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"get kafka consumer offsets failed: <span class="subst">$&#123;consumerOffsetsE.left.get&#125;</span>"</span>)</div><div class="line">      <span class="keyword">val</span> consumerOffsets = consumerOffsetsE.right.get</div><div class="line">      <span class="comment">//从指定offsets处消费kafka</span></div><div class="line">      <span class="comment">//messageHandler = (mmd: MessageAndMetadata[String, String]) =&gt; (mmd.key(), mmd.message())</span></div><div class="line">      <span class="comment">//MessageAndMetadata里包含message的topic message等信息</span></div><div class="line">      <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">K</span>, <span class="type">V</span>, <span class="type">KD</span>, <span class="type">VD</span>, (<span class="type">K</span>, <span class="type">V</span>, <span class="type">String</span>)](</div><div class="line">        ssc, kafkaParams, consumerOffsets, (mmd: <span class="type">MessageAndMetadata</span>[<span class="type">K</span>, <span class="type">V</span>]) =&gt; (mmd.key, mmd.message, mmd.topic)</div><div class="line">      )</div><div class="line">    &#125;</div><div class="line">    messages</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">setOrUpdateOffsets</span></span>(topics: <span class="type">Set</span>[<span class="type">String</span>], groupId: <span class="type">String</span>): <span class="type">Unit</span> =&#123;</div><div class="line">    topics.foreach(topic =&gt; &#123;</div><div class="line">      <span class="keyword">var</span> hasConsumerd = <span class="literal">true</span></div><div class="line">      <span class="keyword">val</span> partitionsE = kc.getPartitions(<span class="type">Set</span>(topic))</div><div class="line">      <span class="keyword">if</span>(partitionsE.isLeft)</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"get kafka partition failed: <span class="subst">$&#123;partitionsE.left.get&#125;</span>"</span>)</div><div class="line">      <span class="keyword">val</span> partitions = partitionsE.right.get</div><div class="line">      <span class="keyword">val</span> consumerOffsetsE = kc.getConsumerOffsets(groupId, partitions)</div><div class="line">      <span class="keyword">if</span>(consumerOffsetsE.isLeft) hasConsumerd = <span class="literal">false</span></div><div class="line">      <span class="comment">//某个groupid首次没有offset信息，会报错从头开始读</span></div><div class="line">      <span class="keyword">if</span>(hasConsumerd)&#123; <span class="comment">// 消费过</span></div><div class="line">        <span class="comment">/**</span></div><div class="line">          * 如果streaming程序执行的时候出现kafka.common.OffsetOutOfRangeException</div><div class="line">          * 说明zk上保存的offsets已经过时，即kafka的定时清理策略已经将包含该offsets的文件删除</div><div class="line">          * 针对这种情况，只要判断一下zk伤的consumerOffsets和earliestLeaderOffsets的大小</div><div class="line">          * 如果consumerOffsets比earliestLeaderOffsets小的话，说明consumerOffsets过时</div><div class="line">          * 这时把consumerOffsets更新为earliestLeaderOffsets</div><div class="line">          */</div><div class="line">        <span class="keyword">val</span> earliestLeaderOffsetsE = kc.getEarliestLeaderOffsets(partitions)</div><div class="line">        <span class="keyword">if</span>(earliestLeaderOffsetsE.isLeft)</div><div class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"get earliest leader offsets failed: <span class="subst">$&#123;earliestLeaderOffsetsE.left.get&#125;</span>"</span>)</div><div class="line">        <span class="keyword">val</span> earliestLeaderOffsets = earliestLeaderOffsetsE.right.get</div><div class="line">        <span class="keyword">val</span> consumerOffsets = consumerOffsetsE.right.get</div><div class="line">        <span class="comment">//可能只存在部分分区consumerOffsets过时，所以只更新过时分区的consumerOffsets为earliestLeaderOffsets</span></div><div class="line">        <span class="keyword">var</span> offsets: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">Long</span>] = <span class="type">Map</span>()</div><div class="line">        consumerOffsets.foreach(&#123;<span class="keyword">case</span>(tp, n) =&gt;</div><div class="line">          <span class="keyword">val</span> earliestLeaderOffset = earliestLeaderOffsets(tp).offset</div><div class="line">          <span class="keyword">if</span>(n &lt; earliestLeaderOffset)&#123;</div><div class="line">            println(<span class="string">"consumer group: "</span> + groupId + <span class="string">",topic: "</span> + tp.topic + <span class="string">",partition: "</span> + tp.partition +</div><div class="line">            <span class="string">" offsets已过时，更新为: "</span> + earliestLeaderOffset)</div><div class="line">            offsets += (tp -&gt; earliestLeaderOffset)</div><div class="line">          &#125;</div><div class="line">        &#125;)</div><div class="line">        <span class="keyword">if</span> (!offsets.isEmpty)&#123;</div><div class="line">          kc.setConsumerOffsets(groupId, offsets)</div><div class="line">        &#125;</div><div class="line">      &#125;<span class="keyword">else</span>&#123; <span class="comment">// 没有消费过</span></div><div class="line">        <span class="keyword">val</span> reset = kafkaParams.get(<span class="string">"auto.offset.reset"</span>).map(_.toLowerCase)</div><div class="line">        <span class="keyword">var</span> leaderOffsets: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">LeaderOffset</span>] = <span class="literal">null</span></div><div class="line">        <span class="keyword">if</span>(reset == <span class="type">Some</span>(<span class="string">"smallest"</span>))&#123; <span class="comment">// 从头消费</span></div><div class="line">          <span class="keyword">val</span> leaderOffsetsE = kc.getEarliestLeaderOffsets(partitions)</div><div class="line">          <span class="keyword">if</span>(leaderOffsetsE.isLeft)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"get earliest leader offsets failed: <span class="subst">$&#123;leaderOffsetsE.left.get&#125;</span>"</span>)</div><div class="line">          leaderOffsets = leaderOffsetsE.right.get</div><div class="line">        &#125;<span class="keyword">else</span>&#123; <span class="comment">// 从最新offset处消费</span></div><div class="line">          <span class="keyword">val</span> leaderOffsetsE = kc.getLatestLeaderOffsets(partitions)</div><div class="line">          <span class="keyword">if</span>(leaderOffsetsE.isLeft)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"get latest leader offsets failed: <span class="subst">$&#123;leaderOffsetsE.left.get&#125;</span>"</span>)</div><div class="line">          leaderOffsets = leaderOffsetsE.right.get</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">val</span> offsets = leaderOffsets.map&#123;</div><div class="line">          <span class="keyword">case</span>(tp, offset) =&gt; (tp, offset.offset)</div><div class="line">        &#125;</div><div class="line">        kc.setConsumerOffsets(groupId, offsets)</div><div class="line">      &#125;</div><div class="line">    &#125;)</div><div class="line">  &#125;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">updateZKOffsets</span></span>(rdd: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>)]): <span class="type">Unit</span> =&#123;</div><div class="line">    <span class="keyword">val</span> groupId = kafkaParams.get(<span class="string">"group.id"</span>).get</div><div class="line">    <span class="keyword">val</span> offsetsList = rdd.asInstanceOf[<span class="type">HasOffsetRanges</span>].offsetRanges</div><div class="line">    <span class="keyword">for</span>(offsets &lt;- offsetsList)&#123;</div><div class="line">      <span class="keyword">val</span> topicAndPartition = <span class="type">TopicAndPartition</span>(offsets.topic, offsets.partition)</div><div class="line">      <span class="keyword">val</span> o = kc.setConsumerOffsets(groupId, <span class="type">Map</span>((topicAndPartition, offsets.untilOffset)))</div><div class="line">      <span class="keyword">if</span>(o.isLeft)&#123;</div><div class="line">        println(<span class="string">s"Error updating the offset to Kafka cluster: <span class="subst">$&#123;o.left.get&#125;</span>"</span>)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<pre><code>SparkKafkaStreaming.scala
</code></pre><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line">import kafka.serializer.StringDecoder</div><div class="line">import org.apache.log4j.&#123;Level, Logger&#125;</div><div class="line">import org.apache.spark.SparkConf</div><div class="line">import org.apache.spark.streaming.kafka.KafkaManager</div><div class="line">import org.apache.spark.streaming.&#123;Durations, Seconds, StreamingContext&#125;</div><div class="line">import org.apache.spark.rdd.RDD</div><div class="line">object SparkKafkaStreaming &#123;</div><div class="line">  def processRdd(rdd: RDD[(String, String, String)]): Unit = &#123;</div><div class="line">    rdd.foreach(println)</div><div class="line">  &#125;</div><div class="line">  def main(args: Array[String]) &#123;</div><div class="line">    if (args.length &lt; 3) &#123;</div><div class="line">      System.err.println(</div><div class="line">        s"""</div><div class="line">           |Usage: DirectKafkaWordCount &lt;brokers&gt; &lt;topics&gt; &lt;groupid&gt;</div><div class="line">           |  &lt;brokers&gt; is a list of one or more Kafka brokers</div><div class="line">           |    &lt;topics&gt; is a list of one or more kafka topics to consume from</div><div class="line">           |      &lt;groupid&gt; is a consume group</div><div class="line">           |</div><div class="line">         """.stripMargin</div><div class="line">      )</div><div class="line">      System.exit(1)</div><div class="line">    &#125;</div><div class="line">    Logger.getLogger("org").setLevel(Level.WARN)</div><div class="line">    val Array(brokers, topics, groupId) = args</div><div class="line">    //create context with 2 second batch interval</div><div class="line">    val sparkConf = new SparkConf().setAppName("DirectKafkaWordCount")</div><div class="line">    sparkConf.setMaster("local[2]")</div><div class="line">    sparkConf.set("spakr.streaming.kafka.maxRatePerPartition", "5")</div><div class="line">    sparkConf.set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")</div><div class="line">    val ssc = new StreamingContext(sparkConf, Durations.seconds(5))</div><div class="line">    ssc.sparkContext.setLogLevel("WARN")</div><div class="line">    //create direct kafka stream with brokers and topics</div><div class="line">    val topicsSet = topics.split(",").toSet</div><div class="line">    val kafkaParams = Map[String, String](</div><div class="line">      "metadata.broker.list" -&gt; brokers,</div><div class="line">      "group.id" -&gt; groupId, //con_group</div><div class="line">      "auto.offset.reset" -&gt; "smallest"</div><div class="line">    )</div><div class="line">    val km = new KafkaManager(kafkaParams)</div><div class="line">    val messages = km.createDirectStream[String, String, StringDecoder, StringDecoder](</div><div class="line">      ssc, kafkaParams, topicsSet</div><div class="line">    )</div><div class="line">    messages.foreachRDD(rdd =&gt; &#123;</div><div class="line">      if(!rdd.isEmpty())&#123;</div><div class="line">        processRdd(rdd)</div><div class="line">        km.updateZKOffsets(rdd)</div><div class="line">      &#125;</div><div class="line">    &#125;)</div><div class="line">    ssc.start()</div><div class="line">    ssc.awaitTermination()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="hbase"><a href="#hbase" class="headerlink" title="hbase"></a>hbase</h1><h3 id="配置文件-4"><a href="#配置文件-4" class="headerlink" title="配置文件"></a>配置文件</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">//Here you have to set the path where you want HBase to store its files.</div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line">//Here you have to set the path where you want HBase to store its built</div><div class="line">in zookeeper files.</div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/zk1/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/hbase/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>Temporary directory on the local filesystem.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.maxClientCnxns<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>35<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost:2182,localhost:2183,localhost:2184<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure>
<h3 id="启动hbase服务"><a href="#启动hbase服务" class="headerlink" title="启动hbase服务"></a>启动hbase服务</h3><pre><code>start-hbase.sh
</code></pre><h3 id="启动zookeeper的node"><a href="#启动zookeeper的node" class="headerlink" title="启动zookeeper的node"></a>启动zookeeper的node</h3><pre><code>hbase-daemon.sh start master
</code></pre><h3 id="启动命令行交互模式"><a href="#启动命令行交互模式" class="headerlink" title="启动命令行交互模式"></a>启动命令行交互模式</h3><pre><code>hbase shell
</code></pre><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> hbaseconf = <span class="type">HBaseConfiguration</span>.create()</div><div class="line">hbaseconf.set(<span class="string">"hbase.zookeeper.quorum"</span>, <span class="string">"localhost"</span>)</div><div class="line">hbaseconf.set(<span class="string">"hbase.zookeeper.property.clientPort"</span>, <span class="string">"2182"</span>)</div><div class="line"><span class="keyword">val</span> table = <span class="keyword">new</span> <span class="type">HTable</span>(hbaseconf, tablename)</div><div class="line"><span class="keyword">val</span> theput = <span class="keyword">new</span> <span class="type">Put</span>(<span class="type">Bytes</span>.toBytes(<span class="string">"001"</span>))</div><div class="line"><span class="keyword">val</span> family = <span class="string">"info"</span></div><div class="line"><span class="keyword">val</span> qualifier = <span class="string">"name"</span></div><div class="line"><span class="keyword">val</span> value = <span class="string">"xerxes"</span></div><div class="line">theput.addColumn(<span class="type">Bytes</span>.toBytes(family),<span class="type">Bytes</span>.toBytes(qualifier),<span class="type">Bytes</span>.toBytes(value))</div><div class="line">table.put(theput)</div><div class="line">table.close()</div></pre></td></tr></table></figure>
<h1 id="spark"><a href="#spark" class="headerlink" title="spark"></a>spark</h1><h1 id="mesos"><a href="#mesos" class="headerlink" title="mesos"></a>mesos</h1><p>  git clone <a href="https://gitbox.apache.org/repos/asf/mesos.git" target="_blank" rel="external">https://gitbox.apache.org/repos/asf/mesos.git</a></p>
<h1 id="hadoop"><a href="#hadoop" class="headerlink" title="hadoop"></a>hadoop</h1><h1 id="hive"><a href="#hive" class="headerlink" title="hive"></a>hive</h1><h1 id="livy"><a href="#livy" class="headerlink" title="livy"></a>livy</h1><ol>
<li>在livy-env.sh中配置<blockquote>
<p>export SPARK_HOME=/Users/zhangyaxing/Desktop/spark<br>export HADOOP_CONF_DIR=/Users/zhangyaxing/Desktop/hadoop-2.4.1/conf</p>
</blockquote>
</li>
<li>启动livy<blockquote>
<p>./bin/livy-server start  </p>
</blockquote>
</li>
</ol>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/08/04/爬虫小结/" rel="next" title="爬虫小结">
                <i class="fa fa-chevron-left"></i> 爬虫小结
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/08/04/java学习笔记/" rel="prev" title="java学习笔记">
                java学习笔记 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="file:///Users/zhangyaxing/Desktop/hexo/猫头.jpg"
               alt="xerxes" />
          <p class="site-author-name" itemprop="name">xerxes</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#zookeeper"><span class="nav-number">1.</span> <span class="nav-text">zookeeper</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#配置文件"><span class="nav-number">1.0.1.</span> <span class="nav-text">配置文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#命令行操作"><span class="nav-number">1.0.2.</span> <span class="nav-text">命令行操作</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#kafka"><span class="nav-number">2.</span> <span class="nav-text">kafka</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#配置文件-1"><span class="nav-number">2.0.1.</span> <span class="nav-text">配置文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启动kafka-broker"><span class="nav-number">2.0.2.</span> <span class="nav-text">启动kafka broker</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建topic"><span class="nav-number">2.0.3.</span> <span class="nav-text">创建topic</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建后，使用-–describe-来查看一下"><span class="nav-number">2.0.4.</span> <span class="nav-text">创建后，使用 –describe 来查看一下</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#现在我们分别在两个终端上运行下面的命令来测试生产消息和消费消息。"><span class="nav-number">2.0.5.</span> <span class="nav-text">现在我们分别在两个终端上运行下面的命令来测试生产消息和消费消息。</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#flume"><span class="nav-number">3.</span> <span class="nav-text">flume</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#配置文件-2"><span class="nav-number">3.0.1.</span> <span class="nav-text">配置文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#命令行操作-1"><span class="nav-number">3.0.2.</span> <span class="nav-text">命令行操作</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#flume-—–-gt-kafka"><span class="nav-number">4.</span> <span class="nav-text">flume —–> kafka</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#配置文件-3"><span class="nav-number">4.0.1.</span> <span class="nav-text">配置文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启动flume连接到kafka"><span class="nav-number">4.0.2.</span> <span class="nav-text">启动flume连接到kafka</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启动kafka消费者接受数据"><span class="nav-number">4.0.3.</span> <span class="nav-text">启动kafka消费者接受数据</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#kafka-—–-gt-spark-streaming"><span class="nav-number">5.</span> <span class="nav-text">kafka —–> spark streaming</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#什么是Spark-Streaming"><span class="nav-number">5.0.1.</span> <span class="nav-text">什么是Spark Streaming</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#自己管理offset"><span class="nav-number">5.0.2.</span> <span class="nav-text">自己管理offset</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#编写代码"><span class="nav-number">5.0.3.</span> <span class="nav-text">编写代码</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#hbase"><span class="nav-number">6.</span> <span class="nav-text">hbase</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#配置文件-4"><span class="nav-number">6.0.1.</span> <span class="nav-text">配置文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启动hbase服务"><span class="nav-number">6.0.2.</span> <span class="nav-text">启动hbase服务</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启动zookeeper的node"><span class="nav-number">6.0.3.</span> <span class="nav-text">启动zookeeper的node</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启动命令行交互模式"><span class="nav-number">6.0.4.</span> <span class="nav-text">启动命令行交互模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#代码"><span class="nav-number">6.0.5.</span> <span class="nav-text">代码</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#spark"><span class="nav-number">7.</span> <span class="nav-text">spark</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#mesos"><span class="nav-number">8.</span> <span class="nav-text">mesos</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#hadoop"><span class="nav-number">9.</span> <span class="nav-text">hadoop</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#hive"><span class="nav-number">10.</span> <span class="nav-text">hive</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#livy"><span class="nav-number">11.</span> <span class="nav-text">livy</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xerxes</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	





  





  





  






  





  

  

  

  

</body>
</html>
