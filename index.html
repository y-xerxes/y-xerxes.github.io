<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta property="og:type" content="website">
<meta property="og:title" content="y-xerxes's Blog">
<meta property="og:url" content="http://yoursite.com/child/index.html">
<meta property="og:site_name" content="y-xerxes's Blog">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="y-xerxes's Blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/child/"/>





  <title> y-xerxes's Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">y-xerxes's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2018/10/11/spark-mesos-airflow/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xerxes">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="file:///Users/zhangyaxing/Desktop/hexo/猫头.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="y-xerxes's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/10/11/spark-mesos-airflow/" itemprop="url">
                  spark+mesos+airflow
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-10-11T22:11:58+08:00">
                2018-10-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><blockquote>
<p>Mesos and Spark are powerful technologies for processing large workloads on a distributed cluster. Airflow is a framework to write, schedule, and monitor jobs. In conjunction, these three technologies provide a powerful way build out workflows backed by large datasets.</p>
</blockquote>
<h1 id="Spark-with-Mesos"><a href="#Spark-with-Mesos" class="headerlink" title="Spark with Mesos"></a>Spark with Mesos</h1><blockquote>
<p>mesos类似于一个抽象化的linux核心。在mesos上运行framework，由scheduler和executor组成。scheduler接收mesos master传来的resource，在mesos nodes上启动executors。</p>
</blockquote>
<h1 id="Airflow-with-Spark"><a href="#Airflow-with-Spark" class="headerlink" title="Airflow with Spark"></a>Airflow with Spark</h1><blockquote>
<p>To run Spark with Airflow, we’ll use the SparkSubmitOperator, which essentially wraps the spark-submit command. The details of how to use this operator are in the README. We’ll run Airflow with the CeleryExecutor, with Redis and Postgresql for persistence. It’s important to keep in mind, however, that the actual work is not being done on the Celery workers but on the Mesos nodes. There’s also a MesosExecutor with which Airflow would directly distribute its tasks onto the Mesos cluster.</p>
</blockquote>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2018/08/04/airflow/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xerxes">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="file:///Users/zhangyaxing/Desktop/hexo/猫头.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="y-xerxes's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/08/04/airflow/" itemprop="url">
                  airflow
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-04T19:49:16+08:00">
                2018-08-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="构建与原理"><a href="#构建与原理" class="headerlink" title="构建与原理"></a>构建与原理</h1><ol>
<li>组建<br> airflow作为调度工具，由Webserver、Scheduler、Worker三个组件互相配合完成工作。三个组件之间没有强依赖关系，依靠共用数据库和消息队列完成调度任务。因此，在多台机器上部署airflow，配置相同的元数据库和消息队列，以此来实现airflow的集群模式。</li>
<li>工作原理<br> 1) airflow启动时，会将dag中的相关信息写入数据库。<br> 2) scheduler会按照指定频次查询数据库，检测是否有需要触发的任务。<br> 3) 当scheduler检测到需要触发的任务时，会向消息队列发送一条Message。<br> 4) Celery会定时查询消息队列中，是否有Message。当检测到Message时，会将Message中包含的任务信息下发给Worker，由Worker执行具体任务。<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1> pip install airflow<br> 或者：<br> pip install -i <a href="https://pypi.tuna.tsinghua.edu.cn/simple" target="_blank" rel="external">https://pypi.tuna.tsinghua.edu.cn/simple</a> airflow</li>
</ol>
<h1 id="初始化数据库"><a href="#初始化数据库" class="headerlink" title="初始化数据库"></a>初始化数据库</h1><pre><code>airflow initdb
</code></pre><h1 id="修改默认数据库"><a href="#修改默认数据库" class="headerlink" title="修改默认数据库"></a>修改默认数据库</h1><pre><code>找到$AIRFLOW_HOME/airflow.cfg配置文件，进行如下修改:
    sql_alchemy_conn = mysql://root:rootroot@localhost:3306/airflow
到mysql中创建新库
    create database airflow;
重新初始化服务器数据库
    airflow initdb
</code></pre><h1 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h1><pre><code>airflow webserver
</code></pre><h1 id="测试和验证"><a href="#测试和验证" class="headerlink" title="测试和验证"></a>测试和验证</h1><pre><code>1). 先运行一下python文件，如果你的脚本没有抛出异常，这意味着你代码中没有可怕的错误，并且你的Airflow环境是健全的。
2). 命令行元数据验证
    airflow list_dags
    airflow list_tasks dag_name
    airflow list_tasks dag_name --tree
    airflow test dag_name task_name datetime
</code></pre><h1 id="启动任务-scheduler启动后，DAG目录下的dags就会根据设定的时间定时启动"><a href="#启动任务-scheduler启动后，DAG目录下的dags就会根据设定的时间定时启动" class="headerlink" title="启动任务[scheduler启动后，DAG目录下的dags就会根据设定的时间定时启动]"></a>启动任务[scheduler启动后，DAG目录下的dags就会根据设定的时间定时启动]</h1><pre><code>airflow scheduler
</code></pre><h1 id="切换CeleryExecutor"><a href="#切换CeleryExecutor" class="headerlink" title="切换CeleryExecutor"></a>切换CeleryExecutor</h1><pre><code>why？
    1. 默认是使用的SequentialExecutor, 只能顺次执行任务。
    2. Only works with the CeleryExecutor, sorry 
how？
    sudo pip install celery
</code></pre>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2018/08/04/docker/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xerxes">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="file:///Users/zhangyaxing/Desktop/hexo/猫头.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="y-xerxes's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/08/04/docker/" itemprop="url">
                  docker
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-04T19:47:37+08:00">
                2018-08-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li><p>下载SQL Server<br> Xerxes% docker pull microsoft/mssql-server-linux</p>
</li>
<li><p>启动Docker镜像<br> Xerxes% docker run -d –name sql_server_demo -e’ACCEPT_EULA=Y’ -e’SA_PASSWORD=zyxing,0513’ -p1433:1433 microsoft/mssql-server-linux</p>
</li>
<li><p>检查Docker容器<br> Xerxes% docker ps</p>
</li>
<li><p>安装sql-cli<br> Xerxes% sudo npm install -g sql-cli</p>
</li>
<li><p>更改SA密码<br> Xerxes% sudo docker exec -it sql_server_demo /opt/mssql-tools/bin/sqlcmd \<br>-S localhost -U SA -P ‘zyxing,0513’ \<br>-Q ‘ALTER LOGIN sa WITH PASSWORD=”zyxing,0513”‘</p>
</li>
<li><p>连接到SQL Server<br> Xerxes%  sudo docker exec -it sql_server_demo “bash”</p>
</li>
<li><p>一旦进入容器，用sqlcmd本地连接。Sqlcmd默认不在路径中，因此您必须指定完整路径。<br> @89191dab957e:/# /opt/mssql-tools/bin/sqlcmd -S localhost -U SA -P ‘zyxing,0513’</p>
</li>
<li><p>启动容器<br> docker container start ‘container’</p>
</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2018/08/04/java学习笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xerxes">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="file:///Users/zhangyaxing/Desktop/hexo/猫头.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="y-xerxes's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/08/04/java学习笔记/" itemprop="url">
                  java学习笔记
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-04T19:47:08+08:00">
                2018-08-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="接口与抽象类的区别"><a href="#接口与抽象类的区别" class="headerlink" title="接口与抽象类的区别"></a>接口与抽象类的区别</h1><h3 id="抽象类（abstract-class）："><a href="#抽象类（abstract-class）：" class="headerlink" title="抽象类（abstract class）："></a>抽象类（abstract class）：</h3><pre><code>使用abstract修饰符修饰的类。官方点的定义就是：如果一个类没有包含足够多的信息来描述一个具体的对象，这样的类就是抽象类。
抽象方法：只声明，不实现。
一个类中含有抽象方法（被abstract修饰），那么这个类必须被声明为抽象类（被abstract修饰）。
</code></pre><h3 id="接口（interface）："><a href="#接口（interface）：" class="headerlink" title="接口（interface）："></a>接口（interface）：</h3><pre><code>官方定义：接口在java中是一个抽象类型，是抽象方法的集合。一个类通过继承接口的方式，从而继承接口的抽象方法。
接口中没有构造方式（因为接口不是类）
接口中的方法必须是抽象的（不能实现）
接口中除了static、final变量，不能有其他变量
接口支持多继承（一个类可以实现多个接口）
</code></pre><h3 id="抽象类和接口的区别："><a href="#抽象类和接口的区别：" class="headerlink" title="抽象类和接口的区别："></a>抽象类和接口的区别：</h3><pre><code>抽象类中可以有已经实现了的方法，也可以有被abstract修饰的方法（抽象方法），但是接口要求只能包含抽象方法.
抽象类使用extends关键字来继承抽象类。如果子类不是抽象类的话，它需要提供抽象类中所有声明的方法的实现。子类使用关键字implements来实现接口。它需要提供接口中所有声明的方法的实现.
抽象类可以有构造器，而接口不能有构造器.
抽象方法可以有public、protected和default这些修饰符 
</code></pre><p>接口方法默认修饰符是public。你不可以使用其它修饰符。</p>
<h1 id="修饰符访问限定"><a href="#修饰符访问限定" class="headerlink" title="修饰符访问限定"></a>修饰符访问限定</h1><pre><code>范围  private     default     protected   public
同类  √   √   √   √
同包中的类       √   √   √
同包中的类，不同包的子类            √   √
所有类                 √
</code></pre><h1 id="Java中堆内存和栈内存详解"><a href="#Java中堆内存和栈内存详解" class="headerlink" title="Java中堆内存和栈内存详解"></a>Java中堆内存和栈内存详解</h1><blockquote>
<p>Java把内存分成两种，一种叫做<code>栈内存</code>，一种叫做<code>堆内存</code>.</p>
<h3 id="栈内存"><a href="#栈内存" class="headerlink" title="栈内存"></a>栈内存</h3><p>栈内存用来存储<code>基本数据类型的对象</code>和<code>自定义对象的引用</code>。栈内存是线程私有的。<br>当在一段代码块中定义一个变量时，java就在栈中为这个变量分配内存空间，当超过变量的作用域后，java会自动释放掉为该变量分配的内存空间，该内存空间可以立刻被另作他用。</p>
<h3 id="堆内存"><a href="#堆内存" class="headerlink" title="堆内存"></a>堆内存</h3><p>堆内存用于存放由new创建的对象和数组。堆内存是所有线程共有的。<br>在堆中分配的内存，由java虚拟机自动垃圾回收器来管理。在堆中产生了一个数组或者对象后，还可以在栈中定义一个特殊的变量，这个变量的取值等于数组或者对象在堆内存中的首地址，在栈中的这个特殊的变量就变成了数组或者对象的引用变量，以后就可以在程序中使用栈内存中的引用变量来访问堆中的数组或者对象.<br>引用变量是普通变量，定义时在栈中分配内存，引用变量在程序运行到作用域外释放。而数组＆对象本身在堆中分配，即使程序运行到使用new产生数组和对象的语句所在地代码块之外，数组和对象本身占用的堆内存也不会被释放，数组和对象在没有引用变量指向它的时候，才变成垃圾，不能再被使用，但是仍然占着内存，在随后的一个不确定的时间被垃圾回收器释放掉。这个也是java比较占内存的主要原因，实际上，栈中的变量指向堆内存中的变量，这就是 Java 中的指针! </p>
</blockquote>
<h1 id="内部类"><a href="#内部类" class="headerlink" title="内部类"></a>内部类</h1><h3 id="什么是内部类"><a href="#什么是内部类" class="headerlink" title="什么是内部类"></a>什么是内部类</h3><blockquote>
<p>可以将一个类的定义放在另一个类的内部，这就是内部类。<br>内部类隐式的持有外部类的引用，，可以访问外部类的所有成员，即使该成员是私有的。它无法被单独创建，必须先创建外部类实例.</p>
</blockquote>
<h3 id="为什么需要内部类，内部类的作用"><a href="#为什么需要内部类，内部类的作用" class="headerlink" title="为什么需要内部类，内部类的作用"></a>为什么需要内部类，内部类的作用</h3><pre><code>1.完善多重继承
    每个内部类都能独立地继承一个（接口的）实现，所以无论外围类是否已经继承了某个（接口的）实现，对于内部类都没有影响。
2.闭包与回调
3.lambda表达式
4.匿名内部类
    Runnable接口的匿名内部类实现
</code></pre><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo</span></span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</div><div class="line">        Runnable r = <span class="keyword">new</span> Runnable()&#123;</div><div class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</div><div class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">5</span>; i++)&#123;</div><div class="line">                    System.out.print(i + <span class="string">" "</span>);</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125;;</div><div class="line">        Thread t = <span class="keyword">new</span> Thread(r);</div><div class="line">        t.start();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Thread thread = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable()&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;);</div></pre></td></tr></table></figure>
<h1 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h1><h3 id="error和exception有什么区别"><a href="#error和exception有什么区别" class="headerlink" title="error和exception有什么区别"></a>error和exception有什么区别</h3><blockquote>
<p>error表示系统级的错误，是java运行环境内部错误或者硬件问题，不能指望程序来处理这样的问题，除了退出运行外别无选择，它是Java虚拟机抛出的。<br>exception表示程序需要捕捉、需要处理的异常，是由与程序设计的不完善而出现的问题，程序必须处理的问题</p>
</blockquote>
<h3 id="运行时异常和一般异常有何不同"><a href="#运行时异常和一般异常有何不同" class="headerlink" title="运行时异常和一般异常有何不同"></a>运行时异常和一般异常有何不同</h3>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2018/08/04/大数据/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xerxes">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="file:///Users/zhangyaxing/Desktop/hexo/猫头.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="y-xerxes's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/08/04/大数据/" itemprop="url">
                  大数据
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-04T19:46:26+08:00">
                2018-08-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>[TOC]</p>
<h1 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h1><h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><pre><code>1.把zookeeper文件夹复制三份，我们仅修改\conf\zoo.cfg
    tickTime=2000
    initLimit=5
    syncLimit=2
    dataDir=/usr/local/zk0/data
    dataLogDir=/usr/local/zk0/logs
    clientPort=2184
    server.0=127.0.0.1:8880:7770
    server.1=127.0.0.1:8881:7771
    server.2=127.0.0.1:8882:7772
2.分别在文件夹/tmp/zookeeper/data00,data01和data02下面新建myid文件，文件内容只有一个数字，代表zookeeper节点的唯一id，即要确保此id在集群内唯一，且要跟配置文件中的server.0、server.1、server.2 对应上。
</code></pre><h3 id="命令行操作"><a href="#命令行操作" class="headerlink" title="命令行操作"></a>命令行操作</h3><pre><code>./zkServer.sh start &amp; #启动zookeeper服务器
./zkServer.sh status#查看状态
./zkCli.sh -server 127.0.0.1:2182 #启动客户端
</code></pre><h1 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h1><h3 id="配置文件-1"><a href="#配置文件-1" class="headerlink" title="配置文件"></a>配置文件</h3><pre><code>仅仅修改server.properties文件，把\config\server.properties文件复制2份，分别是server.properties，server_1.properties，server_2.properties，

0.文件server.properties
    broker.id=0
    listeners=PLAINTEXT://localhost:9092
    log.dirs=/tmp/kafka-logs-0
    num.partitions=3
    zookeeper.connect=localhost:2184,localhost:2182,localhost:2183

1.文件server_1.properties
    broker.id=1
    listeners=PLAINTEXT://localhost:9093
    log.dirs=/tmp/kafka-logs-1
    num.partitions=3
    zookeeper.connect=localhost:2184,localhost:2182,localhost:2183

2.文件server_2.properties
    broker.id=2
    listeners=PLAINTEXT://localhost:9094
    log.dirs=/tmp/kafka-logs-2
    num.partitions=3
    zookeeper.connect=localhost:2184,localhost:2182,localhost:2183
</code></pre><h3 id="启动kafka-broker"><a href="#启动kafka-broker" class="headerlink" title="启动kafka broker"></a>启动kafka broker</h3><pre><code>bin/kafka-server-start.sh -daemon config/server.properties
bin/kafka-server-start.sh -daemon config/server_1.properties
bin/kafka-server-start.sh -daemon config/server_2.properties
</code></pre><h3 id="创建topic"><a href="#创建topic" class="headerlink" title="创建topic"></a>创建topic</h3><pre><code>bin/kafka-topics.sh --create --zookeeper localhost:2182 --replication-factor 3 --partitions 1 --topic mytopic
</code></pre><h3 id="创建后，使用-–describe-来查看一下"><a href="#创建后，使用-–describe-来查看一下" class="headerlink" title="创建后，使用 –describe 来查看一下"></a>创建后，使用 –describe 来查看一下</h3><pre><code>bin/kafka-topics.sh --describe --zookeeper localhost:2182 --topic mytopic
</code></pre><h3 id="现在我们分别在两个终端上运行下面的命令来测试生产消息和消费消息。"><a href="#现在我们分别在两个终端上运行下面的命令来测试生产消息和消费消息。" class="headerlink" title="现在我们分别在两个终端上运行下面的命令来测试生产消息和消费消息。"></a>现在我们分别在两个终端上运行下面的命令来测试生产消息和消费消息。</h3><pre><code># 终端 A 生产消息
$ bin/kafka-console-producer.sh --broker-list localhost:9092 --topic mytopic
# 终端 B 消费消息
$ bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic mytopic
</code></pre><h1 id="flume"><a href="#flume" class="headerlink" title="flume"></a>flume</h1><h3 id="配置文件-2"><a href="#配置文件-2" class="headerlink" title="配置文件"></a>配置文件</h3><pre><code>1.修改 flume-env.sh 配置文件,主要是JAVA_HOME变量设置
2.cp conf/flume-conf.properties.template conf/exec.conf
    示例：
        # Name the components(成分) on this agent
        a2.sources = r2
        a2.sinks = k2
        a2.channels = c2
        # Describe/configure the source
        a2.sources.r2.type = exec
        a2.sources.r2.channels = c2
        a2.sources.r2.command=tail -n +0 -F /Users/zhangyaxing/Desktop/flume-1.6.0/test.log
        # Describe the sink
        a2.sinks.k2.type = logger
        # Use a channel which buffers events in memory
        a2.channels.c2.type = memory
        a2.channels.c2.capacity = 1000
        a2.channels.c2.transactionCapacity = 100
        # Bind the source and sink to the channel
        a2.sources.r2.channels = c2
        a2.sinks.k2.channel = c2
</code></pre><h3 id="命令行操作-1"><a href="#命令行操作-1" class="headerlink" title="命令行操作"></a>命令行操作</h3><pre><code>验证安装：
    flume-ng version
启动flume：
    flume-ng agent --conf conf/ -f conf/exec.conf -Dflume.root.logger=DEBUG,console -n a2
</code></pre><h1 id="flume-—–-gt-kafka"><a href="#flume-—–-gt-kafka" class="headerlink" title="flume —–&gt; kafka"></a>flume —–&gt; kafka</h1><blockquote>
<p>Flume与Kafka整合就是接口的实现，将Kafka的producer API实现为Flume的sink。简单理解就是将Flume的输出（sinks）作为Kafka的输入（producer）。</p>
<h3 id="配置文件-3"><a href="#配置文件-3" class="headerlink" title="配置文件"></a>配置文件</h3><pre><code>a1.sources = s1
a1.sinks = k1
a1.channels = c1
# a1 : name of agent
# Describe/configure the source
a1.sources.s1.type=exec
a1.sources.s1.command=tail -F /Users/zhangyaxing/Desktop/flume-1.6.0/test.log
a1.sources.s1.channels=c1
# Describe the sink
a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k1.topic = flumeTest  
a1.sinks.k1.brokerList = localhost:9092,localhost:9093,localhost:9094
agent.sinks.k1.serializer.class=kafka.serializer.StringEncoder  
a1.sinks.k1.channel = c1 
# Use a channel which buffers events in memory
a1.channels.c1.type = memory
a1.channels.c1.capacity = 10000
a1.channels.c1.transactionCapacity = 100
# Bind the source and sink to the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
</code></pre><h3 id="启动flume连接到kafka"><a href="#启动flume连接到kafka" class="headerlink" title="启动flume连接到kafka"></a>启动flume连接到kafka</h3><pre><code>flume-ng agent -n a1 -c conf/ -f conf/flume-conf.properties -Dflume.root.logger=INFO,console  
</code></pre><h3 id="启动kafka消费者接受数据"><a href="#启动kafka消费者接受数据" class="headerlink" title="启动kafka消费者接受数据"></a>启动kafka消费者接受数据</h3><pre><code>kafka-console-consumer.sh --zookeeper localhost:2182,localhost:2183,localhost:2184 --topic flumeTest --from-beginning
</code></pre></blockquote>
<h1 id="kafka-—–-gt-spark-streaming"><a href="#kafka-—–-gt-spark-streaming" class="headerlink" title="kafka —–&gt; spark streaming"></a>kafka —–&gt; spark streaming</h1><h3 id="什么是Spark-Streaming"><a href="#什么是Spark-Streaming" class="headerlink" title="什么是Spark Streaming"></a>什么是Spark Streaming</h3><blockquote>
<p>流式处理是把连续不断的数据输入分割成单元数据块来处理。<br>Spark Streaming对Spark核心API进行了相应的扩展，支持高吞吐、低延迟、可扩展的流式数据处理。</p>
</blockquote>
<h3 id="自己管理offset"><a href="#自己管理offset" class="headerlink" title="自己管理offset"></a>自己管理offset</h3><blockquote>
<p>为了让Spark Streaming消费kafka的数据不丢数据，可以创建Kafka Direct DStream，由Spark Streaming自己管理offset，并不是存到zookeeper。启用S​​park Streaming的 checkpoints是存储偏移量的最简单方法，因为它可以在Spark的框架内轻松获得。 checkpoints将应用程序的状态保存到HDFS，以便在故障时可以恢复。如果发生故障，Spark Streaming应用程序可以从checkpoints偏移范围读取消息。但是，Spark Streaming checkpoints在应用程序修改后由于从checkpoint反序列化失败而无法恢复，因此不是非常可靠，特别是如果您将此机制用于关键生产应用程序，另外，基于zookeeper的offset可视化工具将无法使用。我们不建议通过Spark checkpoints来管理偏移量。因此本文将手动存储offset到zookeeper，完全自我掌控offset。</p>
</blockquote>
<h3 id="编写代码"><a href="#编写代码" class="headerlink" title="编写代码"></a>编写代码</h3><pre><code>KafkaManager.scala
</code></pre><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> org.apache.spark.streaming.kafka</div><div class="line"><span class="keyword">import</span> kafka.common.<span class="type">TopicAndPartition</span></div><div class="line"><span class="keyword">import</span> kafka.message.<span class="type">MessageAndMetadata</span></div><div class="line"><span class="keyword">import</span> kafka.serializer.<span class="type">Decoder</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkException</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming.<span class="type">StreamingContext</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.<span class="type">InputDStream</span></div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka.<span class="type">KafkaCluster</span>.<span class="type">LeaderOffset</span></div><div class="line"><span class="keyword">import</span> scala.reflect.<span class="type">ClassTag</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">KafkaManager</span>(<span class="params">val kafkaParams: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]</span>) <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</div><div class="line">  <span class="comment">// KafkaCluster in Spark is overwrited by myself</span></div><div class="line">  <span class="keyword">private</span> <span class="keyword">val</span> kc = <span class="keyword">new</span> <span class="type">KafkaCluster</span>(kafkaParams)</div><div class="line">  <span class="comment">//根据offset创建DStream</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">createDirectStream</span></span>[<span class="type">K</span>: <span class="type">ClassTag</span>,</div><div class="line">                        <span class="type">V</span>: <span class="type">ClassTag</span>,</div><div class="line">                        <span class="type">KD</span> &lt;: <span class="type">Decoder</span>[<span class="type">K</span>]: <span class="type">ClassTag</span>,</div><div class="line">                        <span class="type">VD</span> &lt;: <span class="type">Decoder</span>[<span class="type">V</span>]: <span class="type">ClassTag</span></div><div class="line">                        ](ssc: <span class="type">StreamingContext</span>,</div><div class="line">                          kafkaParams: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>],</div><div class="line">                          topics: <span class="type">Set</span>[<span class="type">String</span>]): <span class="type">InputDStream</span>[(<span class="type">K</span>, <span class="type">V</span>, <span class="type">String</span>)] = &#123;</div><div class="line">    <span class="keyword">val</span> groupId = kafkaParams.get(<span class="string">"group.id"</span>).get</div><div class="line">    <span class="comment">//在zookeeper上读取offsets前先根据实际情况更新offsets</span></div><div class="line">    setOrUpdateOffsets(topics, groupId)</div><div class="line">    <span class="comment">//从zookeeper上读取offset开始消费message</span></div><div class="line">    <span class="keyword">val</span> messages = &#123;</div><div class="line">      <span class="keyword">val</span> partitionsE = kc.getPartitions(topics)</div><div class="line">      <span class="keyword">if</span>(partitionsE.isLeft)</div><div class="line">        <span class="comment">// s"xx $&#123;&#125;" 字符串插值</span></div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"get kafka partition failed: <span class="subst">$&#123;partitionsE.left.get&#125;</span>"</span>)</div><div class="line">      <span class="keyword">val</span> partitions = partitionsE.right.get</div><div class="line">      <span class="keyword">val</span> consumerOffsetsE = kc.getConsumerOffsets(groupId, partitions)</div><div class="line">      <span class="keyword">if</span>(consumerOffsetsE.isLeft)</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"get kafka consumer offsets failed: <span class="subst">$&#123;consumerOffsetsE.left.get&#125;</span>"</span>)</div><div class="line">      <span class="keyword">val</span> consumerOffsets = consumerOffsetsE.right.get</div><div class="line">      <span class="comment">//从指定offsets处消费kafka</span></div><div class="line">      <span class="comment">//messageHandler = (mmd: MessageAndMetadata[String, String]) =&gt; (mmd.key(), mmd.message())</span></div><div class="line">      <span class="comment">//MessageAndMetadata里包含message的topic message等信息</span></div><div class="line">      <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">K</span>, <span class="type">V</span>, <span class="type">KD</span>, <span class="type">VD</span>, (<span class="type">K</span>, <span class="type">V</span>, <span class="type">String</span>)](</div><div class="line">        ssc, kafkaParams, consumerOffsets, (mmd: <span class="type">MessageAndMetadata</span>[<span class="type">K</span>, <span class="type">V</span>]) =&gt; (mmd.key, mmd.message, mmd.topic)</div><div class="line">      )</div><div class="line">    &#125;</div><div class="line">    messages</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">setOrUpdateOffsets</span></span>(topics: <span class="type">Set</span>[<span class="type">String</span>], groupId: <span class="type">String</span>): <span class="type">Unit</span> =&#123;</div><div class="line">    topics.foreach(topic =&gt; &#123;</div><div class="line">      <span class="keyword">var</span> hasConsumerd = <span class="literal">true</span></div><div class="line">      <span class="keyword">val</span> partitionsE = kc.getPartitions(<span class="type">Set</span>(topic))</div><div class="line">      <span class="keyword">if</span>(partitionsE.isLeft)</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"get kafka partition failed: <span class="subst">$&#123;partitionsE.left.get&#125;</span>"</span>)</div><div class="line">      <span class="keyword">val</span> partitions = partitionsE.right.get</div><div class="line">      <span class="keyword">val</span> consumerOffsetsE = kc.getConsumerOffsets(groupId, partitions)</div><div class="line">      <span class="keyword">if</span>(consumerOffsetsE.isLeft) hasConsumerd = <span class="literal">false</span></div><div class="line">      <span class="comment">//某个groupid首次没有offset信息，会报错从头开始读</span></div><div class="line">      <span class="keyword">if</span>(hasConsumerd)&#123; <span class="comment">// 消费过</span></div><div class="line">        <span class="comment">/**</span></div><div class="line">          * 如果streaming程序执行的时候出现kafka.common.OffsetOutOfRangeException</div><div class="line">          * 说明zk上保存的offsets已经过时，即kafka的定时清理策略已经将包含该offsets的文件删除</div><div class="line">          * 针对这种情况，只要判断一下zk伤的consumerOffsets和earliestLeaderOffsets的大小</div><div class="line">          * 如果consumerOffsets比earliestLeaderOffsets小的话，说明consumerOffsets过时</div><div class="line">          * 这时把consumerOffsets更新为earliestLeaderOffsets</div><div class="line">          */</div><div class="line">        <span class="keyword">val</span> earliestLeaderOffsetsE = kc.getEarliestLeaderOffsets(partitions)</div><div class="line">        <span class="keyword">if</span>(earliestLeaderOffsetsE.isLeft)</div><div class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"get earliest leader offsets failed: <span class="subst">$&#123;earliestLeaderOffsetsE.left.get&#125;</span>"</span>)</div><div class="line">        <span class="keyword">val</span> earliestLeaderOffsets = earliestLeaderOffsetsE.right.get</div><div class="line">        <span class="keyword">val</span> consumerOffsets = consumerOffsetsE.right.get</div><div class="line">        <span class="comment">//可能只存在部分分区consumerOffsets过时，所以只更新过时分区的consumerOffsets为earliestLeaderOffsets</span></div><div class="line">        <span class="keyword">var</span> offsets: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">Long</span>] = <span class="type">Map</span>()</div><div class="line">        consumerOffsets.foreach(&#123;<span class="keyword">case</span>(tp, n) =&gt;</div><div class="line">          <span class="keyword">val</span> earliestLeaderOffset = earliestLeaderOffsets(tp).offset</div><div class="line">          <span class="keyword">if</span>(n &lt; earliestLeaderOffset)&#123;</div><div class="line">            println(<span class="string">"consumer group: "</span> + groupId + <span class="string">",topic: "</span> + tp.topic + <span class="string">",partition: "</span> + tp.partition +</div><div class="line">            <span class="string">" offsets已过时，更新为: "</span> + earliestLeaderOffset)</div><div class="line">            offsets += (tp -&gt; earliestLeaderOffset)</div><div class="line">          &#125;</div><div class="line">        &#125;)</div><div class="line">        <span class="keyword">if</span> (!offsets.isEmpty)&#123;</div><div class="line">          kc.setConsumerOffsets(groupId, offsets)</div><div class="line">        &#125;</div><div class="line">      &#125;<span class="keyword">else</span>&#123; <span class="comment">// 没有消费过</span></div><div class="line">        <span class="keyword">val</span> reset = kafkaParams.get(<span class="string">"auto.offset.reset"</span>).map(_.toLowerCase)</div><div class="line">        <span class="keyword">var</span> leaderOffsets: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">LeaderOffset</span>] = <span class="literal">null</span></div><div class="line">        <span class="keyword">if</span>(reset == <span class="type">Some</span>(<span class="string">"smallest"</span>))&#123; <span class="comment">// 从头消费</span></div><div class="line">          <span class="keyword">val</span> leaderOffsetsE = kc.getEarliestLeaderOffsets(partitions)</div><div class="line">          <span class="keyword">if</span>(leaderOffsetsE.isLeft)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"get earliest leader offsets failed: <span class="subst">$&#123;leaderOffsetsE.left.get&#125;</span>"</span>)</div><div class="line">          leaderOffsets = leaderOffsetsE.right.get</div><div class="line">        &#125;<span class="keyword">else</span>&#123; <span class="comment">// 从最新offset处消费</span></div><div class="line">          <span class="keyword">val</span> leaderOffsetsE = kc.getLatestLeaderOffsets(partitions)</div><div class="line">          <span class="keyword">if</span>(leaderOffsetsE.isLeft)</div><div class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"get latest leader offsets failed: <span class="subst">$&#123;leaderOffsetsE.left.get&#125;</span>"</span>)</div><div class="line">          leaderOffsets = leaderOffsetsE.right.get</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">val</span> offsets = leaderOffsets.map&#123;</div><div class="line">          <span class="keyword">case</span>(tp, offset) =&gt; (tp, offset.offset)</div><div class="line">        &#125;</div><div class="line">        kc.setConsumerOffsets(groupId, offsets)</div><div class="line">      &#125;</div><div class="line">    &#125;)</div><div class="line">  &#125;</div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">updateZKOffsets</span></span>(rdd: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>)]): <span class="type">Unit</span> =&#123;</div><div class="line">    <span class="keyword">val</span> groupId = kafkaParams.get(<span class="string">"group.id"</span>).get</div><div class="line">    <span class="keyword">val</span> offsetsList = rdd.asInstanceOf[<span class="type">HasOffsetRanges</span>].offsetRanges</div><div class="line">    <span class="keyword">for</span>(offsets &lt;- offsetsList)&#123;</div><div class="line">      <span class="keyword">val</span> topicAndPartition = <span class="type">TopicAndPartition</span>(offsets.topic, offsets.partition)</div><div class="line">      <span class="keyword">val</span> o = kc.setConsumerOffsets(groupId, <span class="type">Map</span>((topicAndPartition, offsets.untilOffset)))</div><div class="line">      <span class="keyword">if</span>(o.isLeft)&#123;</div><div class="line">        println(<span class="string">s"Error updating the offset to Kafka cluster: <span class="subst">$&#123;o.left.get&#125;</span>"</span>)</div><div class="line">      &#125;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<pre><code>SparkKafkaStreaming.scala
</code></pre><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line">import kafka.serializer.StringDecoder</div><div class="line">import org.apache.log4j.&#123;Level, Logger&#125;</div><div class="line">import org.apache.spark.SparkConf</div><div class="line">import org.apache.spark.streaming.kafka.KafkaManager</div><div class="line">import org.apache.spark.streaming.&#123;Durations, Seconds, StreamingContext&#125;</div><div class="line">import org.apache.spark.rdd.RDD</div><div class="line">object SparkKafkaStreaming &#123;</div><div class="line">  def processRdd(rdd: RDD[(String, String, String)]): Unit = &#123;</div><div class="line">    rdd.foreach(println)</div><div class="line">  &#125;</div><div class="line">  def main(args: Array[String]) &#123;</div><div class="line">    if (args.length &lt; 3) &#123;</div><div class="line">      System.err.println(</div><div class="line">        s"""</div><div class="line">           |Usage: DirectKafkaWordCount &lt;brokers&gt; &lt;topics&gt; &lt;groupid&gt;</div><div class="line">           |  &lt;brokers&gt; is a list of one or more Kafka brokers</div><div class="line">           |    &lt;topics&gt; is a list of one or more kafka topics to consume from</div><div class="line">           |      &lt;groupid&gt; is a consume group</div><div class="line">           |</div><div class="line">         """.stripMargin</div><div class="line">      )</div><div class="line">      System.exit(1)</div><div class="line">    &#125;</div><div class="line">    Logger.getLogger("org").setLevel(Level.WARN)</div><div class="line">    val Array(brokers, topics, groupId) = args</div><div class="line">    //create context with 2 second batch interval</div><div class="line">    val sparkConf = new SparkConf().setAppName("DirectKafkaWordCount")</div><div class="line">    sparkConf.setMaster("local[2]")</div><div class="line">    sparkConf.set("spakr.streaming.kafka.maxRatePerPartition", "5")</div><div class="line">    sparkConf.set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")</div><div class="line">    val ssc = new StreamingContext(sparkConf, Durations.seconds(5))</div><div class="line">    ssc.sparkContext.setLogLevel("WARN")</div><div class="line">    //create direct kafka stream with brokers and topics</div><div class="line">    val topicsSet = topics.split(",").toSet</div><div class="line">    val kafkaParams = Map[String, String](</div><div class="line">      "metadata.broker.list" -&gt; brokers,</div><div class="line">      "group.id" -&gt; groupId, //con_group</div><div class="line">      "auto.offset.reset" -&gt; "smallest"</div><div class="line">    )</div><div class="line">    val km = new KafkaManager(kafkaParams)</div><div class="line">    val messages = km.createDirectStream[String, String, StringDecoder, StringDecoder](</div><div class="line">      ssc, kafkaParams, topicsSet</div><div class="line">    )</div><div class="line">    messages.foreachRDD(rdd =&gt; &#123;</div><div class="line">      if(!rdd.isEmpty())&#123;</div><div class="line">        processRdd(rdd)</div><div class="line">        km.updateZKOffsets(rdd)</div><div class="line">      &#125;</div><div class="line">    &#125;)</div><div class="line">    ssc.start()</div><div class="line">    ssc.awaitTermination()</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="hbase"><a href="#hbase" class="headerlink" title="hbase"></a>hbase</h1><h3 id="配置文件-4"><a href="#配置文件-4" class="headerlink" title="配置文件"></a>配置文件</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></div><div class="line">//Here you have to set the path where you want HBase to store its files.</div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line">//Here you have to set the path where you want HBase to store its built</div><div class="line">in zookeeper files.</div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/zk1/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>/hbase/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>Temporary directory on the local filesystem.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.maxClientCnxns<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>35<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost:2182,localhost:2183,localhost:2184<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure>
<h3 id="启动hbase服务"><a href="#启动hbase服务" class="headerlink" title="启动hbase服务"></a>启动hbase服务</h3><pre><code>start-hbase.sh
</code></pre><h3 id="启动zookeeper的node"><a href="#启动zookeeper的node" class="headerlink" title="启动zookeeper的node"></a>启动zookeeper的node</h3><pre><code>hbase-daemon.sh start master
</code></pre><h3 id="启动命令行交互模式"><a href="#启动命令行交互模式" class="headerlink" title="启动命令行交互模式"></a>启动命令行交互模式</h3><pre><code>hbase shell
</code></pre><h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> hbaseconf = <span class="type">HBaseConfiguration</span>.create()</div><div class="line">hbaseconf.set(<span class="string">"hbase.zookeeper.quorum"</span>, <span class="string">"localhost"</span>)</div><div class="line">hbaseconf.set(<span class="string">"hbase.zookeeper.property.clientPort"</span>, <span class="string">"2182"</span>)</div><div class="line"><span class="keyword">val</span> table = <span class="keyword">new</span> <span class="type">HTable</span>(hbaseconf, tablename)</div><div class="line"><span class="keyword">val</span> theput = <span class="keyword">new</span> <span class="type">Put</span>(<span class="type">Bytes</span>.toBytes(<span class="string">"001"</span>))</div><div class="line"><span class="keyword">val</span> family = <span class="string">"info"</span></div><div class="line"><span class="keyword">val</span> qualifier = <span class="string">"name"</span></div><div class="line"><span class="keyword">val</span> value = <span class="string">"xerxes"</span></div><div class="line">theput.addColumn(<span class="type">Bytes</span>.toBytes(family),<span class="type">Bytes</span>.toBytes(qualifier),<span class="type">Bytes</span>.toBytes(value))</div><div class="line">table.put(theput)</div><div class="line">table.close()</div></pre></td></tr></table></figure>
<h1 id="spark"><a href="#spark" class="headerlink" title="spark"></a>spark</h1><h1 id="mesos"><a href="#mesos" class="headerlink" title="mesos"></a>mesos</h1><ol>
<li>手动安装与编译<br>git clone <a href="https://gitbox.apache.org/repos/asf/mesos.git" target="_blank" rel="external">https://gitbox.apache.org/repos/asf/mesos.git</a><br>cd mesos<br>./bootstrap<br>mkdir build<br>cd build<br>../configure<br>make<br>make check<br>make install</li>
<li>brew安装<br>brew install mesos (安装位置：/usr/local/Cellar/mesos/1.6.1)</li>
<li>启动master节点<br>/usr/local/sbin/mesos-master –registry=in_memory –ip=127.0.0.1</li>
</ol>
<h1 id="hadoop"><a href="#hadoop" class="headerlink" title="hadoop"></a>hadoop</h1><h1 id="hive"><a href="#hive" class="headerlink" title="hive"></a>hive</h1><h1 id="livy"><a href="#livy" class="headerlink" title="livy"></a>livy</h1><ol>
<li>在livy-env.sh中配置<blockquote>
<p>export SPARK_HOME=/Users/zhangyaxing/Desktop/spark<br>export HADOOP_CONF_DIR=/Users/zhangyaxing/Desktop/hadoop-2.4.1/conf</p>
</blockquote>
</li>
<li>启动livy<blockquote>
<p>./bin/livy-server start  </p>
</blockquote>
</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2018/08/04/爬虫小结/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xerxes">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="file:///Users/zhangyaxing/Desktop/hexo/猫头.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="y-xerxes's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/08/04/爬虫小结/" itemprop="url">
                  爬虫小结
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-04T19:45:52+08:00">
                2018-08-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="爬虫汇总"><a href="#爬虫汇总" class="headerlink" title="爬虫汇总"></a>爬虫汇总</h1><h3 id="得到页面"><a href="#得到页面" class="headerlink" title="得到页面"></a>得到页面</h3><ul>
<li>requests<blockquote>
<p>  import requests</p>
<p>  url = “#”<br>  html = requests.get(url)<br>  html.text #文本<br>  html.content #二进制文本</p>
</blockquote>
</li>
</ul>
<h3 id="解析页面"><a href="#解析页面" class="headerlink" title="解析页面"></a>解析页面</h3><ol>
<li><p>bs4</p>
<blockquote>
<p>  from bs4 improt BeautifulSoup</p>
<p>  html = requests.get(url)<br>  soup = BeautifulSoup(html.text,’lxml’)<br>  soup.find_all(‘tag’)</p>
</blockquote>
</li>
<li><p>re</p>
<blockquote>
<p>  import re</p>
<p>  html = requests.get(url)<br>  pattern = re.compile(r’ ‘)<br>  content = re.findall(pattern,html)</p>
</blockquote>
</li>
</ol>
<h3 id="自动化测试工具-浏览器"><a href="#自动化测试工具-浏览器" class="headerlink" title="自动化测试工具+浏览器"></a>自动化测试工具+浏览器</h3><ul>
<li>selenium+phantomjs<blockquote>
<p>  from selenium import webdriver<br>  from selenium.webdriver.common.by import By<br>  from selenium.webdriver.support.ui import WebDriverWait<br>  from selenium.webdriver.support import expected_conditions</p>
<p>  driver = webdriver.PhantomJS() #phantomjs需提前设置好path<br>  wait = WebDriverWait(driver,10) #等待页面加载</p>
<p>  driver.get(“#”)</p>
<p>  input = wait.until(</p>
<pre><code>expected_conditions.presence_of_element_located((By.CSS_SELECTOR,&apos;#q&apos;)) #等待一定条件的内容加载完毕
</code></pre><p>  )</p>
<p>  input.send_keys(‘’) #输入内容</p>
</blockquote>
</li>
</ul>
<h3 id="can’t-find-a-amtching-set-of-capacity"><a href="#can’t-find-a-amtching-set-of-capacity" class="headerlink" title="can’t find a amtching set of capacity"></a>can’t find a amtching set of capacity</h3><p>from selenium.webdriver.common.desired_capabilities import DesiredCapabilities<br>cap = DesiredCapabilities().FIREFOX<br>cap[“marionette”] = False<br>driver = webdriver.Firefox(capabilities=cap)</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2018/08/04/uwsgi-nginx-supervisor部署/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xerxes">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="file:///Users/zhangyaxing/Desktop/hexo/猫头.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="y-xerxes's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/08/04/uwsgi-nginx-supervisor部署/" itemprop="url">
                  uwsgi+nginx+supervisor部署
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-04T19:45:18+08:00">
                2018-08-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>flask + uwsgi + nginx</p>
<h1 id="安装uwsgi"><a href="#安装uwsgi" class="headerlink" title="安装uwsgi"></a>安装uwsgi</h1><p>pip install uwsgi</p>
<h1 id="配置uwsgi"><a href="#配置uwsgi" class="headerlink" title="配置uwsgi"></a>配置uwsgi</h1><p>[uwsgi]<br>socket = 0.0.0.0:9402 //端口号与应用对应<br>module = run:app<br>master = true<br>processes = 3<br>chdir = /Users/zhangyaxing/desktop/itfin<br>vacuum = true<br>plugin = python, http</p>
<h1 id="运行uwsgi"><a href="#运行uwsgi" class="headerlink" title="运行uwsgi"></a>运行uwsgi</h1><p>uwsgi –ini config.ini</p>
<h1 id="安装nginx"><a href="#安装nginx" class="headerlink" title="安装nginx"></a>安装nginx</h1><p>1.<br>    wget <a href="http://nginx.org/download/nginx-1.5.6.tar.gz" target="_blank" rel="external">http://nginx.org/download/nginx-1.5.6.tar.gz</a><br>    tar xf nginx-1.5.6.tar.gz<br>    cd nginx-1.5.6<br>    ./configure –prefix=/usr/local/nginx-1.5.6<br>    –with-http_stub_status_module<br>    –with-http_gzip_static_module<br>    make &amp;&amp; make install<br>2.<br>    sudo apt-get install nginx</p>
<h1 id="配置nginx"><a href="#配置nginx" class="headerlink" title="配置nginx"></a>配置nginx</h1><p>1.<br>    nginx.conf<br>        server {<br>            listen       80;<br>            server_name  localhost;</p>
<pre><code>    #charset koi8-r;
    #access_log  logs/host.access.log  main;
    location / {
        root   html;
        index  index.html index.htm;
        include  uwsgi_params;
        uwsgi_pass  0.0.0.0:9402;
}}
</code></pre><p>2.<br>    sudo rm /etc/nginx/sites-enabled/default<br>3.<br>    sudo ln -s /home/cncert/itfin/itfin-master-latest/economy/nginx.conf /etc/nginx/conf.d/<br>4.<br>    sudo /etc/init.d/nginx restart</p>
<h1 id="supervisor"><a href="#supervisor" class="headerlink" title="supervisor"></a>supervisor</h1><ol>
<li>安装<br> sudo pip install supervisor</li>
<li><p>配置<br> [program:run]</p>
<h1 id="启动命令入口"><a href="#启动命令入口" class="headerlink" title="启动命令入口"></a>启动命令入口</h1><h1 id="uwsgi的路径一定要正确-type-uwsgi可以查看路径"><a href="#uwsgi的路径一定要正确-type-uwsgi可以查看路径" class="headerlink" title="uwsgi的路径一定要正确. $type uwsgi可以查看路径"></a>uwsgi的路径一定要正确. $type uwsgi可以查看路径</h1><p> command=/home/cncert/.local/bin/uwsgi /home/cncert/itfin/itfin-master-latest/economy/config.ini</p>
<h1 id="命令程序所在目录"><a href="#命令程序所在目录" class="headerlink" title="命令程序所在目录"></a>命令程序所在目录</h1><p> directory=/home/cncert/itfin/itfin-master-latest/economy<br> #运行命令的用户名<br> user=cncert<br> autostart=true<br> autorestart=true<br> startsecs=10<br> startretries=10<br> #日志地址<br> stdout_logfile=/home/cncert/itfin/itfin-master-latest/economy/uwsgi_supervisor.log<br> stdout_logfile_maxbytes = 50MB<br> stderr_logfile=/home/cncert/itfin/itfin-master-latest/economy/uwsgi_err.log<br> stderr_logfile_maxbytes = 50MB<br> [supervisord]<br> [supervisorctl]<br> [inet_http_server]<br> port = 127.0.0.1:9001<br> [rpcinterface:supervisor]<br> supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface  </p>
</li>
<li><p>启动<br> sudo supervisord -c supervisord.config</p>
</li>
<li>关闭：<br> supervisorctl stop all    先关闭supervisor启动脚本，之后再关闭supervisord服务<br> kill pid</li>
</ol>
<h1 id="压力测试"><a href="#压力测试" class="headerlink" title="压力测试"></a>压力测试</h1>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/child/2018/08/04/tips/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="xerxes">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="file:///Users/zhangyaxing/Desktop/hexo/猫头.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="y-xerxes's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2018/08/04/tips/" itemprop="url">
                  tips
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-04T19:43:08+08:00">
                2018-08-04
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ol>
<li>hexo更新文章<br> 1). hexo new “file_name”<br> 2). hexo generate<br> 3). hexo deploy</li>
<li>mysqlclient 代替 MySQLdb</li>
<li>linux配置shadowsocks<br>配置文件：<br>{<br>“server”:”<em>“,<br>“server_port”:</em>,<br>“local_address”: “127.0.0.1”,<br>“local_port”:1080,<br>“password”:”<em>bh</em>“,<br>“timeout”:300,<br>“method”:”<em>aes-256-cfb</em>“<br>}<br>启动：<br>ssserver -c shadowsocks.json -d start</li>
<li>ubuntu分辨率<br> 1）. cvt 1680 1050<br> 2）. sudo xrandr –newmode “1680<em>1050_60.00” 146.25 1680 1784 1960 2240 1050 1053 1059 1089 -hsync +vsync<br> 3）. sudo xrandr –addmode VGA-1 “1680</em>1050_60.00”<br> 4）. sudo xrandr –output VGA-1 –mode “1680*1050_60.00”</li>
<li>多思考，不管思考到了什么，记下来然后Google，会有新的发现</li>
<li>ps -ef | grep “进程名字”<br>lsof -nP -iTCP -sTCP:LISTEN | grep “进程id”</li>
<li>后台启动mysql<ol>
<li>mysqld_safe –user=mysql &amp;</li>
<li>brew services start mysql<br>my.cnf位置：/usr/local/etc/my.cnf<br>报错：”Can’t connect to local MySQL server through socket ‘/Applications/MAMP/tmp/mysql/mysql.sock’ (2)”<br>解决：ln -s /tmp/mysql.sock /Applications/MAMP/tmp/mysql</li>
</ol>
</li>
<li>后台启动mongodb<br> sudo mongod –dbpath=/data/db –logpath=/data/db/mongodb.log –fork</li>
<li>为pip添加镜像<br> pip install selenium -i <a href="https://pypi.douban.com/simple/" target="_blank" rel="external">https://pypi.douban.com/simple/</a> –trusted-host pypi.douban.com</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="file:///Users/zhangyaxing/Desktop/hexo/猫头.jpg"
               alt="xerxes" />
          <p class="site-author-name" itemprop="name">xerxes</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">xerxes</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	





  





  





  






  





  

  

  

  

</body>
</html>
